This project was made in the context of the Advanced Machine Learning course from the Faculty of Sciences of the University of Lisbon.

The project was conducted using the [RAVDESS dataset](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio). This datasets *contains 24 professional actors (12 female, 12 male), vocalizing two lexically-matched statements in a neutral North American accent. Speech emotions includes calm, happy, sad, angry, fearful, surprise, and disgust expressions.*

From this data, we had the proposed goals of classifying actors according to their gender and expressed emotion, and comparing the performance of **Convolutional Neural Network** and **Long Short-Term Memory Network** models to complete such task.
